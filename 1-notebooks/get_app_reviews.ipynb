{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get App Reviews of Global Top Sellers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition to Get App Reviews\n",
    "\n",
    "This function retrieves reviews of games from the Steam store using the Steam API. The reviews are saved per batch to comply with the request limit that Steam has set.\n",
    "\n",
    "### Parameters:\n",
    "- `app_id`: The unique identifier for the Steam game whose reviews need to be fetched.\n",
    "- `steamid`: The unique identifier for the Steam user who has left a review for the game.\n",
    "- `recommendationid`: The unique identifier for the review the user has left for the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steam_reviews(app_id):\n",
    "    url = f\"https://store.steampowered.com/appreviews/{app_id}?json=1\"\n",
    "    review_rows = []\n",
    "    cursor = \"*\"\n",
    "    reviews_fetched = 0\n",
    "    api_call_counter = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    while reviews_fetched < 1000 and api_call_counter < 10:\n",
    "        params = {\"json\": 1, \"cursor\": cursor, \"num_per_page\": 100}\n",
    "        api_call_counter += 1\n",
    "        \n",
    "        req_start = time.time()\n",
    "        response = requests.get(url, params=params)\n",
    "        req_duration = time.time() - req_start\n",
    "        if req_duration > 5:\n",
    "            print_log(f\"Warning: Request for App ID {app_id} took {req_duration:.2f} seconds.\")\n",
    "        if response.status_code != 200:\n",
    "            print_log(f\"Failed to fetch reviews for App ID {app_id}, Status Code: {response.status_code}\")\n",
    "            break\n",
    "        data = response.json()\n",
    "        if data.get('success', 0) != 1:\n",
    "            print_log(f\"Error fetching reviews for App ID {app_id}: {data.get('error')}\")\n",
    "            break\n",
    "        \n",
    "        reviews = data.get('reviews', [])\n",
    "        if not reviews:\n",
    "            print_log(f\"No new reviews for App ID {app_id}. Ending fetch.\")\n",
    "            break \n",
    "            \n",
    "        for review in reviews:\n",
    "            review_row = {\n",
    "                \"appid\": app_id,\n",
    "                \"recommendationid\": review.get(\"recommendationid\"),\n",
    "                \"steamid\": review.get(\"author\", {}).get(\"steamid\"),\n",
    "                \"num_games_owned\": review.get(\"author\", {}).get(\"num_games_owned\"),\n",
    "                \"num_reviews_author\": review.get(\"author\", {}).get(\"num_reviews\"),\n",
    "                \"playtime_forever\": review.get(\"author\", {}).get(\"playtime_forever\"),\n",
    "                \"playtime_last_two_weeks\": review.get(\"author\", {}).get(\"playtime_last_two_weeks\"),\n",
    "                \"playtime_at_review\": review.get(\"author\", {}).get(\"playtime_at_review\"),\n",
    "                \"deck_playtime_at_review\": review.get(\"author\", {}).get(\"deck_playtime_at_review\"),\n",
    "                \"last_played\": review.get(\"author\", {}).get(\"last_played\"),\n",
    "                \"timestamp_created\": review.get(\"timestamp_created\"),\n",
    "                \"timestamp_updated\": review.get(\"timestamp_updated\"),\n",
    "                \"voted_up\": review.get(\"voted_up\"),\n",
    "                \"weighted_vote_score\": review.get(\"weighted_vote_score\"),\n",
    "                \"steam_purchase\": review.get(\"steam_purchase\"),\n",
    "                \"received_for_free\": review.get(\"received_for_free\")\n",
    "            }\n",
    "            review_rows.append(review_row)\n",
    "            reviews_fetched += 1\n",
    "            if reviews_fetched >= 1000:\n",
    "                break\n",
    "        \n",
    "        if reviews_fetched >= 1000:\n",
    "            break\n",
    "        \n",
    "        new_cursor = data.get('cursor')\n",
    "        if not new_cursor or new_cursor == cursor:\n",
    "            print_log(f\"No new cursor for App ID {app_id}. Ending fetch.\")\n",
    "            break\n",
    "        cursor = new_cursor\n",
    "        time.sleep(1)\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print_log(f\"Total time for App ID {app_id}: {total_time:.2f} sec, API calls: {api_call_counter}, Reviews fetched: {reviews_fetched}\")\n",
    "    return review_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Script to Obtain Game Reviews\n",
    "\n",
    "Since we have already initially generated a folder per date, we do not need to repeat that line to ensure that the reviews dataset gets saved into the same folder. We have also set the same filters as what we have already set to get the app details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_datetime = datetime.now()\n",
    "params_list = [\n",
    "    {\"filter\": \"globaltopsellers\"},\n",
    "]\n",
    "page_list = list(range(1, 9))\n",
    "params_sr_default = {\n",
    "    \"category1\": 998,\n",
    "    \"ndl\": 1,\n",
    "    \"filter\": \"globaltopsellers\",\n",
    "    \"page\": 1,\n",
    "    \"json\": 1\n",
    "}\n",
    "\n",
    "request_counter = 0\n",
    "all_reviews = []\n",
    "stop_extraction = False  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for update_param in params_list:\n",
    "    if stop_extraction:\n",
    "        break\n",
    "    for page_no in page_list:\n",
    "        param = params_sr_default.copy()\n",
    "        param.update(update_param)\n",
    "        param[\"page\"] = page_no\n",
    "\n",
    "        search_results = get_search_results(param)\n",
    "        print_log(f\"Fetched {len(search_results.get('items', []))} items from page {page_no}.\")\n",
    "\n",
    "        if not search_results.get('items', []):\n",
    "            print_log(\"No more items found on this page â€“ reached the end. Stopping further page requests.\")\n",
    "            stop_extraction = True\n",
    "            break\n",
    "\n",
    "        items = search_results.get(\"items\", [])\n",
    "        for item in items:\n",
    "            appid_match = re.search(r\"steam/\\w+/(\\d+)\", item[\"logo\"])\n",
    "            if appid_match:\n",
    "                app_id = appid_match.group(1)\n",
    "                print_log(f\"Fetching reviews for App ID: {app_id}\")\n",
    "                reviews = get_steam_reviews(app_id)\n",
    "                if reviews:\n",
    "                    all_reviews.extend(reviews)\n",
    "                    reviews_df = pd.DataFrame(all_reviews)\n",
    "                    filename = search_result_folder_path / f\"globaltopsellers_reviews_{execute_datetime.strftime('%Y%m%d')}.csv\"\n",
    "                    reviews_df.to_csv(filename, index=False)\n",
    "                    print_log(f\"Saved: {filename}\")\n",
    "            else:\n",
    "                print_log(\"Failed to extract appid for an item.\")\n",
    "            \n",
    "            request_counter += 1\n",
    "            if request_counter >= 10:\n",
    "                print_log(\"10 requests made, pausing for 10 seconds to comply with rate limit.\")\n",
    "                time.sleep(10)\n",
    "                request_counter = 0\n",
    "\n",
    "        if page_no == max(page_list):\n",
    "            print_log(\"Reached the maximum page limit (page 8). Stopping extraction.\")\n",
    "            stop_extraction = True\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Results\n",
    "\n",
    "Once all the requirements set above had been satisifed, we save the final dataset from the day as a CSV file into the same folder we had initially created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_reviews:\n",
    "    reviews_df = pd.DataFrame(all_reviews)\n",
    "    filename = search_result_folder_path / f\"globaltopsellers_reviews_{execute_datetime.strftime('%Y%m%d')}.csv\"\n",
    "    reviews_df.to_csv(filename, index=False)\n",
    "    print_log(f\"Final CSV file saved to {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging and Cleaning Data\n",
    "\n",
    "In this section, the obtained data over the past few days will be merged together. We start by opening all CSV's with gaming and review data that were collected over the past few days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_directory = Path(__file__).parent if \"__file__\" in globals() else Path().resolve()\n",
    "\n",
    "num_days = 7\n",
    "start_date = datetime.strptime('20250302', '%Y%m%d')\n",
    "\n",
    "date_list = [(start_date + timedelta(days=i)).strftime('%Y%m%d') for i in range(num_days)]\n",
    "\n",
    "games_data = {}\n",
    "reviews_data = {}\n",
    "\n",
    "for date in date_list:\n",
    "    search_result_folder_path = base_directory / f\"search_results_{date}\"  \n",
    "    games_path = search_result_folder_path / f\"globaltopsellers_{date}.csv\"\n",
    "    review_path = search_result_folder_path / f\"globaltopsellers_reviews_{date}.csv\"\n",
    "\n",
    "    if games_path.exists():\n",
    "        games_data[date] = pd.read_csv(games_path)\n",
    "        games_data[date][\"extraction_date\"] = datetime.strptime(date, \"%Y%m%d\")\n",
    "        print(f\"Loaded games data for {date}\")\n",
    "\n",
    "    if review_path.exists():\n",
    "        reviews_data[date] = pd.read_csv(review_path)\n",
    "        reviews_data[date][\"extraction_date\"] = datetime.strptime(date, \"%Y%m%d\")\n",
    "        print(f\"Loaded reviews data for {date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Changing the Game Data\n",
    "\n",
    "First, we change the formatting of the price that is displayed on our dataset to remove the symbols. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_price(price):\n",
    "    try:\n",
    "        clean_price = ''.join([ch for ch in str(price) if ch.isdigit() or ch == '.'])\n",
    "        return float(clean_price) if clean_price else None\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a game is free, `price_overview` will show an NA value. Therefore, we have decided to set the prices of games that are free to the value 0. We have also calculated the `discount_ratio` of games that are currently on sale, again, changing the values of games that are free -- therefore, returning NA value -- as 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in date_list:\n",
    "    if day in games_data:  \n",
    "        games = games_data[day] \n",
    "\n",
    "        ## CONVERT PRICE\n",
    "        games['original_price_numeric'] = games['original_price'].apply(convert_price)\n",
    "        games['discounted_price_numeric'] = games['discounted_price'].apply(convert_price)\n",
    "        games['price_overview_numeric'] = games['price_overview'].apply(convert_price)\n",
    "\n",
    "        ## REPLACE MISSING VALUES WITH 0 FOR FREE GAMES\n",
    "        games.loc[games['is_free'] == True, ['original_price_numeric', 'discounted_price_numeric', 'price_overview_numeric']] = 0\n",
    "\n",
    "        ## CALCULATE DISCOUNT RATIO\n",
    "        games['discount_ratio'] = np.where(\n",
    "            games['original_price_numeric'] > 0,\n",
    "            (games['original_price_numeric'] - games['discounted_price_numeric']) / games['original_price_numeric'],\n",
    "            0  # If original price is zero, set discount ratio to 0\n",
    "        )\n",
    "\n",
    "        ## REPLACE NA VALUES WITH 0\n",
    "        games['discount_ratio'] = games['discount_ratio'].fillna(0)\n",
    "\n",
    "        ## LOG-TRANSFORM PRICE -- HANDLE PRICE VARIABILITY ##\n",
    "        games['log_price'] = np.log1p(games['original_price_numeric'])  # log(price + 1) to avoid log(0)\n",
    "        \n",
    "        games_data[day] = games\n",
    "\n",
    "    else:\n",
    "        print(f\"games_{day} does not exist!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Changing Review Data\n",
    "\n",
    "The variable `voted_up` returns `TRUE` or `FALSE` value. Next, we convert the `voted_up` value to binary `1` for \"Recommended\" and `0` for \"Not Recommended\".\n",
    "\n",
    "Then, we convert `playtime_at_review` and `num_games_owned` to numeric. These two variables represent the hours spent playing the game before leaving a review and the number of games the user owns, respectively.\n",
    "\n",
    "Lastly, we calculate the `weighted_positive` which is the variable we will be using forward to measure whether a user positively recommends the game or not. This variable is a result of calculating the variable `voted_up` with the `weighted_vote_score` -- which is essentially the rate of influence the review has with `1` as the maximum value. \n",
    "\n",
    "For example:\n",
    "- `app_id`: 2246340\n",
    "- `recommendationid`: 189066635\n",
    "- `steamid`: 76561198106660720\n",
    "- `voted_up`: `TRUE`\n",
    "- `weighted_vote_score`: 0.872241854667663574\n",
    "\n",
    "$$ \\text{weighted\\_positive} = \\text{voted\\_up} \\times \\text{weighted\\_vote\\_score} $$\n",
    "$$ \\text{weighted\\_positive} = 1 \\times 0.872241854667663574 = 0.872241854667663574 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in date_list:\n",
    "    if day in reviews_data:  \n",
    "        review = reviews_data[day]\n",
    "    \n",
    "        ## CONVERT VOTED_UP TO BOOLEAN\n",
    "        review['voted_up_bool'] = review['voted_up'].astype(bool)\n",
    "        review['voted_up_binary'] = review['voted_up'].astype(int)  # Convert to binary (1 = Recommended, 0 = Not Recommended)\n",
    "\n",
    "        ## CONVERT TO NUMERIC\n",
    "        review['playtime_at_review'] = pd.to_numeric(review['playtime_at_review'], errors='coerce')\n",
    "        review['num_games_owned'] = pd.to_numeric(review['num_games_owned'], errors='coerce')\n",
    "\n",
    "        ## WEIGHTED POSITIVITY SCORE \n",
    "        review['weighted_positive'] = review['voted_up'] * review['weighted_vote_score']\n",
    "        \n",
    "        reviews_data[day] = review\n",
    "\n",
    "    else:\n",
    "        print(f\"review_{day} does not exist!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for day in date_list:\n",
    "    if day in reviews_data and day in games_data:\n",
    "        review = reviews_data[day]\n",
    "        games = games_data[day] \n",
    "\n",
    "        ## MERGE ON APPID\n",
    "        merged_review = review.merge(games, on='appid', how='inner')\n",
    "\n",
    "        reviews_data[day] = merged_review\n",
    "\n",
    "    else:\n",
    "        print(f\"Either review or games data for {day} does not exist!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a full data frame for each day that we collected data. We merge all the data removing duplicates. We do it in this order, since some columns of both Games and Review can change over time. We want to connect the values that were captured on a certain day, which is why we first join the data frames for a specific day and then merge all dates together. We remove full duplicates, meaning if every single column has the same value as another row, one of the rows is deleted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLLECT ALL REVIEWS DATA PER DATE\n",
    "all_reviews = []\n",
    "\n",
    "for day in date_list:\n",
    "    if day in reviews_data:  \n",
    "        all_reviews.append(reviews_data[day])\n",
    "    else:\n",
    "        print(f\"review data for {day} not found!\")\n",
    "\n",
    "## COMBINE AND REMOVE FULL DUPLICATES \n",
    "if all_reviews:\n",
    "    combined_reviews = pd.concat(all_reviews, ignore_index=True).drop_duplicates()\n",
    "else:\n",
    "    combined_reviews = pd.DataFrame() \n",
    "    \n",
    "combined_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we remove the duplicates by considering these three columns only. That means any rows where recommendationid, steamid, and appid are the same (regardless of differences in other columns) will be dropped, leaving only the first occurrence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_reviews.drop_duplicates(subset=[\"recommendationid\", \"steamid\", \"appid\"], keep = \"first\", inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we remove several columns that are not needed anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_removed = ['logo', 'timestamp_created', 'timestamp_updated', 'type', 'steam_appid', 'supported_languages', 'developers', 'publishers', 'platforms', 'num_reviews']\n",
    "combined_reviews = combined_reviews.drop(columns = columns_removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we save the final dataset into a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_reviews.to_csv(\"combined_reviews.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
